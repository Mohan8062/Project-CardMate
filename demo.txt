# bc_ocr_extractor.py
"""
Business Card OCR + Structured Extractor (clean, focused version)

Features:
- Simple preprocessing (grayscale -> adaptive threshold -> denoise)
- EasyOCR text extraction (line-wise)
- Robust email detection and fixes (handles missing dot before TLD)
- Phone extraction aware of splits and country codes
- Website extraction (with and without http/www)
- Job title extraction (returns probable job title)
- Name extraction (improved heuristics to avoid company-name false positives)
- Company extraction by merging consecutive UPPERCASE lines (multi-line company names)
- Address extraction with pincode & house-number detection + keyword fallback
- Returns structured dict and prints nicely
"""

import re
import cv2
import numpy as np
import easyocr
import matplotlib.pyplot as plt
from collections import OrderedDict

# ---------------------------
# OCR Reader (EasyOCR)
# ---------------------------
reader = easyocr.Reader(["en"], gpu=False)  # change gpu=True if you have GPU

# ---------------------------
# Preprocessing
# ---------------------------
def preprocess_for_cards(image_bgr):
    """
    Focused preprocessing for business cards:
    - convert to gray
    - adaptive threshold to handle varying backgrounds
    - fastNlMeansDenoising to reduce OCR noise
    """
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    # adaptive threshold to binarize text regions
    th = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        blockSize=31,
        C=12
    )
    # denoise
    den = cv2.fastNlMeansDenoising(th, h=20)
    return den

# ---------------------------
# OCR extraction helper
# ---------------------------
def ocr_lines_from_image(img_path):
    img = cv2.imread(img_path)
    if img is None:
        raise FileNotFoundError(f"Image not found: {img_path}")

    proc = preprocess_for_cards(img)
    results = reader.readtext(proc, detail=1)  # list of (bbox, text, prob)
    # sort by top-left y coordinate to keep reading order
    results_sorted = sorted(results, key=lambda r: min(pt[1] for pt in r[0]))
    text_lines = [r[1].strip() for r in results_sorted if r[1].strip()]
    confidences = [r[2] for r in results_sorted]
    avg_conf = float(np.mean(confidences)) if confidences else 0.0

    return {
        "raw_image": img,
        "proc_image": proc,
        "lines": text_lines,
        "confidences": confidences,
        "avg_confidence": avg_conf
    }

# ---------------------------
# Extraction functions
# ---------------------------
def extract_emails(full_text):
    # normal email pattern
    email_re = r"[A-Za-z0-9._%+\-]+@[A-Za-z0-9.\-]+\.[A-Za-z]{2,}"
    emails = re.findall(email_re, full_text)
    if emails:
        # dedupe preserving order
        return list(OrderedDict.fromkeys(emails))

    # fallback: handle missing dot before TLD in compressed text
    compressed = re.sub(r"\s+", "", full_text)
    tlds = r"(com|in|net|org|co|biz|info|edu|gov)"
    fallback_re = rf"[A-Za-z0-9._%+\-]+@[A-Za-z0-9.\-]+(?:{tlds})\b"
    candidates = re.findall(fallback_re, compressed)
    # the above returns only groups (tld) if group used; instead find full matches
    fallback_full = re.findall(rf"[A-Za-z0-9._%+\-]+@[A-Za-z0-9.\-]+(?:com|in|net|org|co|biz|info|edu|gov)\b", compressed)
    fixed = []
    for c in fallback_full:
        # insert dot before trailing tld if absent
        c2 = re.sub(r"(com|in|net|org|co|biz|info|edu|gov)$", r".\1", c)
        # fix common OCR confusions
        c2 = c2.replace("(at)", "@").replace("[at]", "@").replace("(@", "@")
        c2 = c2.replace(",com", ".com").replace("com,", ".com")
        fixed.append(c2)
    return list(OrderedDict.fromkeys(fixed))

def extract_phones(full_text):
    phones = []
    # common patterns: +91 98765 43210, 09876543210, 98765-43210, 044-12345678
    # find digit groups with optional plus, spaces, hyphens, parentheses
    raw = re.findall(r"(?:\+?\d[\d\-\s\(\)]{5,}\d)", full_text)
    for p in raw:
        cleaned = re.sub(r"[^\d+]", "", p)
        # keep plausible lengths: 6 - 14 digits (cover mobiles, landlines with area, country codes)
        digits_only = re.sub(r"[^\d]", "", cleaned)
        if 6 <= len(digits_only) <= 14:
            phones.append(cleaned)
    # sometimes OCR splits digits; catch long contiguous digit groups in compressed text
    compressed = re.sub(r"\s+", "", full_text)
    extra = re.findall(r"\d{6,14}", compressed)
    for e in extra:
        if e not in phones:
            phones.append(e)
    # normalize: remove duplicates preserve order
    return list(OrderedDict.fromkeys(phones))

def extract_websites(full_text):
    # match http(s) and www and bare domains
    web_re = r"(https?://[A-Za-z0-9\-\._~:/\?#\[\]@!$&'()*+,;=%]+|www\.[A-Za-z0-9\-\._]+\.[A-Za-z]{2,}|[A-Za-z0-9\-\._]+\.(com|in|net|org|co|biz|info|io|tech)\b)"
    matches = re.findall(web_re, full_text)
    sites = []
    for m in matches:
        # m may be tuple depending on groups; pick non-empty element
        if isinstance(m, tuple):
            candidate = next((x for x in m if x), "")
        else:
            candidate = m
        candidate = candidate.strip().rstrip(".,;")
        # ensure scheme
        if not candidate.startswith(("http://", "https://", "www.")):
            candidate = candidate
        sites.append(candidate)
    return list(OrderedDict.fromkeys(sites))

# ----- Name heuristics -----
def looks_like_name(line):
    """
    Heuristic for person names:
    - 1-3 words
    - words use Title case (First letter uppercase, rest lowercase)
    - not containing company suffix words
    """
    words = [w for w in re.split(r"\s+", line.strip()) if w]
    if not (1 <= len(words) <= 3):
        return False
    # exclude lines with digits or URLs or emails
    if re.search(r"\d|@|www\.|http", line):
        return False
    company_bad = re.compile(r"\b(pvt|ltd|llp|private|limited|industries|solutions|machines|technologies|services|inc)\b", re.I)
    if company_bad.search(line):
        return False
    # ensure words look like names (Title)
    for w in words:
        # allow initials like "A." or "A.B."
        if re.fullmatch(r"[A-Z]\.", w):
            continue
        if not (w[0].isupper() and (len(w) == 1 or w[1:].islower())):
            return False
    return True

def extract_name(lines):
    # prefer top lines: first 4 lines (business cards often put name near top)
    for i in range(min(4, len(lines))):
        if looks_like_name(lines[i]):
            return lines[i].strip()
    # fallback: any line that looks like name
    for ln in lines:
        if looks_like_name(ln):
            return ln.strip()
    return ""

# ----- Job title extraction -----
def extract_job_title(lines):
    job_keywords = [
        "engineer", "manager", "director", "executive", "consultant", "founder",
        "ceo", "cto", "cfo", "president", "vp", "vice", "coordinator", "lead",
        "head", "officer", "architect", "developer", "designer", "specialist",
        "supervisor", "sales", "marketing", "operations", "administrator"
    ]
    for ln in lines:
        lw = ln.lower()
        # skip noisy short lines (<3 chars) or lines with email/phone/website
        if len(lw) < 3 or "@" in lw or re.search(r"www\.|http", lw):
            continue
        # if a job keyword appears and line is not company-like, take it
        if any(k in lw for k in job_keywords):
            # avoid capturing company lines
            if not re.search(r"\b(pvt|ltd|llp|inc|industries|solutions)\b", lw):
                return ln.strip()
    return ""

# ----- Company extraction -----
def is_all_caps_line(line):
    words = [w for w in re.split(r"\s+", line) if w.isalpha()]
    if not words:
        return False
    # consider line uppercase if majority words are uppercase
    cap_count = sum(1 for w in words if w.isupper())
    return cap_count >= max(1, len(words) // 1)  # strict: mostly uppercase

def extract_company(lines):
    # Merge consecutive uppercase / title-like lines into company candidate
    company_blocks = []
    i = 0
    N = len(lines)
    while i < N:
        if is_all_caps_line(lines[i]):
            block = [lines[i].strip()]
            j = i + 1
            while j < N and (is_all_caps_line(lines[j]) or len(lines[j].split()) <= 3):
                # absorb likely continuation lines (short connectives)
                block.append(lines[j].strip())
                j += 1
            company_blocks.append(" ".join(block))
            i = j
        else:
            i += 1
    if company_blocks:
        # prefer the longest block (more words)
        company = max(company_blocks, key=lambda s: len(s))
        return company
    # fallback: any line containing company suffix
    suffix_re = re.compile(r"\b(pvt\.?\s*ltd|private limited|ltd\.?|llp\b|inc\.?|industries|corporation|technologies|solutions|services)\b", re.I)
    for ln in lines:
        if suffix_re.search(ln):
            return ln.strip()
    return ""

# ----- Address extraction -----
def extract_address(lines):
    # collect address-like groups: lines containing address keywords or pincodes or numbers/house patterns
    addr_keywords = ["road", "street", "nagar", "lane", "tower", "park", "sector",
                     "phase", "building", "block", "pincode", "pin", "near", "opp",
                     "chennai", "bangalore", "coimbatore", "kolkata", "mumbai",
                     "delhi", "hyderabad", "no.", "no", "nos", "addr", "village"]
    addr_candidates = []
    i = 0
    N = len(lines)
    while i < N:
        ln = lines[i].lower()
        # check pincode
        pin_match = re.search(r"\b\d{6}\b", ln)
        house_match = re.search(r"\b\d{1,4}\/?\d{0,4}\b", ln)  # 23 or 23/1 patterns
        if any(k in ln for k in addr_keywords) or pin_match or house_match:
            group = [lines[i].strip()]
            j = i + 1
            # absorb following lines that also look address-like (contain numbers, commas or keywords)
            while j < N and (re.search(r"\d|,|-|road|street|lane|nagar|sector", lines[j].lower())):
                group.append(lines[j].strip())
                j += 1
            addr_candidates.append(", ".join(group))
            i = j
        else:
            i += 1

    # dedupe and return best candidate(s)
    if addr_candidates:
        return list(OrderedDict.fromkeys(addr_candidates))
    return []

# ---------------------------
# Main structured extraction
# ---------------------------
def extract_structured_from_image(img_path, visualize=False):
    ocr_data = ocr_lines_from_image(img_path)
    lines = ocr_data["lines"]
    full_text = "\n".join(lines)
    compressed_text = re.sub(r"\s+", "", full_text)

    structured = {}
    structured["name"] = extract_name(lines)
    structured["job_title"] = extract_job_title(lines)
    structured["company"] = extract_company(lines)
    structured["emails"] = extract_emails(full_text)
    structured["phones"] = extract_phones(full_text)
    structured["websites"] = extract_websites(full_text)
    structured["addresses"] = extract_address(lines)
    structured["ocr_avg_confidence"] = ocr_data["avg_confidence"]

    # optional visualization
    if visualize:
        vis = ocr_data["raw_image"].copy()
        for bbox, text, prob in reader.readtext(preprocess_for_cards(ocr_data["raw_image"]), detail=1):
            # bbox here is approximate because we re-ran readtext; draw roughly
            pts = np.int32(bbox)
            x_min = int(np.min(pts[:,0]))
            y_min = int(np.min(pts[:,1]))
            x_max = int(np.max(pts[:,0]))
            y_max = int(np.max(pts[:,1]))
            cv2.rectangle(vis, (x_min, y_min), (x_max, y_max), (0,255,0), 1)
            cv2.putText(vis, text, (x_min, max(10, y_min-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 3, cv2.LINE_AA)
            cv2.putText(vis, text, (x_min, max(10, y_min-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)

        plt.figure(figsize=(10,6))
        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))
        plt.axis("off")
        plt.title("OCR Visualization")
        plt.show()

    return structured

# ---------------------------
# Simple pretty print
# ---------------------------
def pretty_print_structured(s):
    print("\n===== Extracted Business Card Data =====")
    for k, v in s.items():
        if isinstance(v, list):
            print(f"{k}:")
            if v:
                for item in v:
                    print(f"  - {item}")
            else:
                print("  - (none)")
        else:
            print(f"{k}: {v if v else '(none)'}")
    print("========================================\n")

# ---------------------------
# CLI Run
# ---------------------------
if __name__ == "__main__":
    # ðŸ”¥ Give your business card image path here
    image_path = r"C:\Users\mohanraj\OneDrive\Desktop\finalyr project\Screenshot 2025-08-27 181927.png" # <<-- change this

    # ðŸ”¥ Enable/disable visualization
    visualize = True

    # Run extraction
    result = extract_structured_from_image(image_path, visualize=visualize)

    # Print structured output
    pretty_print_structured(result)
    print("OCR Average Confidence:", result.get("ocr_avg_confidence", 0.0))

